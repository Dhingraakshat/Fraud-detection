{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02c6470",
   "metadata": {},
   "source": [
    "# 05 – XGBoost Meta-Learner (Stacking)  \n",
    "This notebook trains the **stacking meta model** using only the **signals** (including CatBoost if available) produced by the 3 base models:\n",
    "\n",
    "- LightGBM probability (`lgb_proba`)\n",
    "- IsolationForest anomaly risk score (`iforest_score`)\n",
    "- Autoencoder reconstruction-error risk score (`ae_score`)\n",
    "\n",
    "Inputs (produced by the base notebooks):\n",
    "- `oof_lgb.csv`, `test_lgb.csv`\n",
    "- `oof_iforest.csv`, `test_iforest.csv`\n",
    "- `oof_ae.csv`, `test_ae.csv`\n",
    "\n",
    "It produces:\n",
    "- `oof_meta.csv` (OOF meta probabilities on the train period; used for analysis)\n",
    "- `test_meta.csv` (meta probabilities on the future test period)\n",
    "\n",
    "Key requirements implemented:\n",
    "- Time-aware training: meta train is sorted by `TransactionDT`\n",
    "- **Optuna** tuning to maximize **F2-score** at a fixed threshold\n",
    "- **Confusion matrix** + metrics on the test period\n",
    "- **SHAP** explanation of meta model\n",
    "\n",
    "> Threshold is set to `0.05` by default (change once at the top and it updates everywhere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf91898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (Optional) Install dependencies (Colab-safe)\n",
    "try:\n",
    "    import optuna  # noqa: F401\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"optuna\"])\n",
    "\n",
    "try:\n",
    "    import shap  # noqa: F401\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"shap\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    fbeta_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Global config (EDIT HERE)\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "N_SPLITS = 5\n",
    "N_TRIALS = 50\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Detect Colab + mount Drive\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "datapath = \"/content/drive/MyDrive/RThesis/\" if IN_COLAB else \"./\"\n",
    "os.makedirs(datapath, exist_ok=True)\n",
    "\n",
    "print(\"datapath =\", datapath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e510a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load base model outputs\n",
    "# -----------------------------\n",
    "paths_needed = [\n",
    "    \"oof_lgb.csv\", \"test_lgb.csv\",\n",
    "    \"oof_iforest.csv\", \"test_iforest.csv\",\n",
    "    \"oof_ae.csv\", \"test_ae.csv\",\n",
    "    \"oof_cat.csv\", \"test_cat.csv\",\n",
    "    \"y_train.csv\", \"y_test.csv\",\n",
    "    \"train_keys.csv\", \"test_keys.csv\",\n",
    "]\n",
    "for fn in paths_needed:\n",
    "    p = os.path.join(datapath, fn)\n",
    "    assert os.path.exists(p), f\"Missing file: {p}\"\n",
    "\n",
    "oof_lgb = pd.read_csv(os.path.join(datapath, \"oof_lgb.csv\"))\n",
    "oof_if  = pd.read_csv(os.path.join(datapath, \"oof_iforest.csv\"))\n",
    "oof_ae  = pd.read_csv(os.path.join(datapath, \"oof_ae.csv\"))\n",
    "oof_cat = pd.read_csv(os.path.join(datapath, \"oof_cat.csv\"))\n",
    "\n",
    "test_lgb = pd.read_csv(os.path.join(datapath, \"test_lgb.csv\"))\n",
    "test_if  = pd.read_csv(os.path.join(datapath, \"test_iforest.csv\"))\n",
    "test_ae  = pd.read_csv(os.path.join(datapath, \"test_ae.csv\"))\n",
    "test_cat = pd.read_csv(os.path.join(datapath, \"test_cat.csv\"))\n",
    "\n",
    "y_train = pd.read_csv(os.path.join(datapath, \"y_train.csv\"))[\"isFraud\"].astype(int)\n",
    "y_test  = pd.read_csv(os.path.join(datapath, \"y_test.csv\"))[\"isFraud\"].astype(int)\n",
    "\n",
    "train_keys = pd.read_csv(os.path.join(datapath, \"train_keys.csv\"))\n",
    "test_keys  = pd.read_csv(os.path.join(datapath, \"test_keys.csv\"))\n",
    "\n",
    "# Ensure row_id exists\n",
    "if \"row_id\" not in train_keys.columns:\n",
    "    train_keys[\"row_id\"] = np.arange(len(train_keys))\n",
    "if \"row_id\" not in test_keys.columns:\n",
    "    test_keys[\"row_id\"] = np.arange(len(test_keys))\n",
    "\n",
    "print(\"Loaded base outputs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Build meta train/test tables (merge by row_id)\n",
    "# -----------------------------\n",
    "# Keep only required score columns (and keep has_oof if present)\n",
    "def slim(df, score_col):\n",
    "    cols = [\"row_id\", score_col]\n",
    "    extra = [c for c in [\"has_oof\", \"fold\"] if c in df.columns]\n",
    "    cols += extra\n",
    "    return df[cols].copy()\n",
    "\n",
    "oof_lgb_s = slim(oof_lgb, \"lgb_proba\")\n",
    "oof_if_s  = slim(oof_if, \"iforest_score\")\n",
    "oof_ae_s  = slim(oof_ae, \"ae_score\")\n",
    "oof_cat_s = slim(oof_cat, \"cat_proba\")\n",
    "\n",
    "test_lgb_s = slim(test_lgb, \"lgb_proba\")\n",
    "test_if_s  = slim(test_if, \"iforest_score\")\n",
    "test_ae_s  = slim(test_ae, \"ae_score\")\n",
    "test_cat_s = slim(test_cat, \"cat_proba\")\n",
    "\n",
    "# Merge OOF\n",
    "meta_train = train_keys[[\"row_id\", \"TransactionDT\"]].copy()\n",
    "meta_train = meta_train.merge(oof_lgb_s, on=\"row_id\", how=\"left\")\n",
    "meta_train = meta_train.merge(oof_if_s,  on=\"row_id\", how=\"left\")\n",
    "meta_train = meta_train.merge(oof_ae_s,  on=\"row_id\", how=\"left\")\n",
    "meta_train = meta_train.merge(oof_cat_s, on=\"row_id\", how=\"left\")\n",
    "\n",
    "meta_train[\"y_true\"] = y_train.values\n",
    "\n",
    "# Filter to rows where ALL base models provide OOF (no leakage / no missing)\n",
    "score_cols = [\"lgb_proba\", \"iforest_score\", \"ae_score\", \"cat_proba\"]\n",
    "mask = meta_train[score_cols].notnull().all(axis=1)\n",
    "\n",
    "# If has_oof columns exist, also enforce them\n",
    "for c in [c for c in meta_train.columns if c.startswith(\"has_oof\")]:\n",
    "    mask &= meta_train[c].fillna(False).astype(bool)\n",
    "\n",
    "meta_train = meta_train[mask].copy()\n",
    "meta_train = meta_train.sort_values(\"TransactionDT\").reset_index(drop=True)\n",
    "\n",
    "print(\"Meta train shape:\", meta_train.shape)\n",
    "print(\"Meta train fraud rate:\", meta_train[\"y_true\"].mean())\n",
    "print(\"Dropped rows (no full OOF):\", int((~mask).sum()))\n",
    "\n",
    "# Merge TEST\n",
    "meta_test = test_keys[[\"row_id\", \"TransactionDT\"]].copy()\n",
    "meta_test = meta_test.merge(test_lgb_s, on=\"row_id\", how=\"left\")\n",
    "meta_test = meta_test.merge(test_if_s,  on=\"row_id\", how=\"left\")\n",
    "meta_test = meta_test.merge(test_ae_s,  on=\"row_id\", how=\"left\")\n",
    "meta_test = meta_test.merge(test_cat_s, on=\"row_id\", how=\"left\")\n",
    "meta_test[\"y_true\"] = y_test.values\n",
    "meta_test = meta_test.sort_values(\"TransactionDT\").reset_index(drop=True)\n",
    "\n",
    "print(\"Meta test shape:\", meta_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dae734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Prepare matrices\n",
    "# -----------------------------\n",
    "feature_cols = [\"lgb_proba\", \"iforest_score\", \"ae_score\", \"cat_proba\"]\n",
    "\n",
    "X_meta_train = meta_train[feature_cols].values.astype(np.float32)\n",
    "y_meta_train = meta_train[\"y_true\"].values.astype(int)\n",
    "\n",
    "X_meta_test = meta_test[feature_cols].values.astype(np.float32)\n",
    "y_meta_test = meta_test[\"y_true\"].values.astype(int)\n",
    "\n",
    "# scale_pos_weight base\n",
    "n_pos = int(y_meta_train.sum())\n",
    "n_neg = int((1 - y_meta_train).sum())\n",
    "base_spw = max(1.0, n_neg / max(1, n_pos))\n",
    "\n",
    "print(\"Meta base scale_pos_weight:\", base_spw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99117734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def compute_f2(y_true, y_score, threshold=THRESHOLD, beta=2.0):\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "    return fbeta_score(y_true, y_pred, beta=beta, zero_division=0)\n",
    "\n",
    "def evaluate_binary(y_true, y_score, threshold=THRESHOLD, title=\"Model\"):\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f2   = fbeta_score(y_true, y_pred, beta=2.0, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "    try:\n",
    "        ap = average_precision_score(y_true, y_score)\n",
    "    except Exception:\n",
    "        ap = np.nan\n",
    "\n",
    "    print(f\"\\n[{title}]  threshold={threshold}\")\n",
    "    print(f\"Precision: {prec:.4f} | Recall: {rec:.4f} | F2: {f2:.4f} | ROC-AUC: {auc:.4f} | PR-AUC: {ap:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cm)\n",
    "    ax.set_title(f\"{title} – Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    ax.set_xticklabels([\"Non-Fraud\",\"Fraud\"])\n",
    "    ax.set_yticklabels([\"Non-Fraud\",\"Fraud\"])\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC + PR curves\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "        plt.title(f\"{title} – ROC Curve\")\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"ROC curve skipped:\", e)\n",
    "\n",
    "    try:\n",
    "        p, r, _ = precision_recall_curve(y_true, y_score)\n",
    "        plt.figure()\n",
    "        plt.plot(r, p)\n",
    "        plt.title(f\"{title} – Precision-Recall Curve\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"PR curve skipped:\", e)\n",
    "\n",
    "    return {\"precision\": prec, \"recall\": rec, \"f2\": f2, \"roc_auc\": auc, \"pr_auc\": ap, \"cm\": cm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a690c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Optuna tuning (maximize mean CV F2)\n",
    "# -----------------------------\n",
    "def make_params(trial):\n",
    "    return {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 3000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 8),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 20.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5 * base_spw, 2.0 * base_spw, log=True),\n",
    "    }\n",
    "\n",
    "def objective(trial):\n",
    "    params = make_params(trial)\n",
    "\n",
    "    tss = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "    f2s = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tss.split(X_meta_train), start=1):\n",
    "        X_tr, y_tr = X_meta_train[tr_idx], y_meta_train[tr_idx]\n",
    "        X_va, y_va = X_meta_train[va_idx], y_meta_train[va_idx]\n",
    "\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1,\n",
    "            tree_method=\"hist\",\n",
    "            eval_metric=\"aucpr\",\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        proba_va = model.predict_proba(X_va)[:, 1]\n",
    "        f2s.append(compute_f2(y_va, proba_va, threshold=THRESHOLD))\n",
    "\n",
    "    return float(np.mean(f2s))\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"meta_xgb_f2\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"Best CV F2:\", study.best_value)\n",
    "print(\"Best params:\\n\", json.dumps(best_params, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfa700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Train final meta model on full meta-train\n",
    "# -----------------------------\n",
    "final_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"random_state\": SEED,\n",
    "    \"n_jobs\": -1,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"eval_metric\": \"aucpr\",\n",
    "    **best_params,\n",
    "}\n",
    "\n",
    "best_params_path = os.path.join(datapath, \"best_params_meta_xgb.json\")\n",
    "with open(best_params_path, \"w\") as f:\n",
    "    json.dump(final_params, f, indent=2)\n",
    "print(\"Saved best params to:\", best_params_path)\n",
    "\n",
    "meta_model = xgb.XGBClassifier(**final_params)\n",
    "meta_model.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "# Test evaluation\n",
    "meta_test_proba = meta_model.predict_proba(X_meta_test)[:, 1]\n",
    "_ = evaluate_binary(y_meta_test, meta_test_proba, threshold=THRESHOLD, title=\"Meta XGBoost (Test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33535d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# OOF predictions for meta model (optional but useful for analysis)\n",
    "# -----------------------------\n",
    "tss = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "\n",
    "oof_meta = np.full(len(X_meta_train), np.nan, dtype=float)\n",
    "oof_fold = np.full(len(X_meta_train), -1, dtype=int)\n",
    "has_oof = np.zeros(len(X_meta_train), dtype=bool)\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(tss.split(X_meta_train), start=1):\n",
    "    X_tr, y_tr = X_meta_train[tr_idx], y_meta_train[tr_idx]\n",
    "    X_va, y_va = X_meta_train[va_idx], y_meta_train[va_idx]\n",
    "\n",
    "    m = xgb.XGBClassifier(**final_params)\n",
    "    m.fit(X_tr, y_tr)\n",
    "\n",
    "    proba_va = m.predict_proba(X_va)[:, 1]\n",
    "    oof_meta[va_idx] = proba_va\n",
    "    oof_fold[va_idx] = fold\n",
    "    has_oof[va_idx] = True\n",
    "\n",
    "    print(f\"Fold {fold}/{N_SPLITS} F2={compute_f2(y_va, proba_va):.4f}\")\n",
    "\n",
    "mask = has_oof\n",
    "_ = evaluate_binary(y_meta_train[mask], oof_meta[mask], threshold=THRESHOLD, title=\"Meta XGBoost OOF (Train)\")\n",
    "print(\"OOF coverage:\", mask.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Save meta predictions\n",
    "# -----------------------------\n",
    "oof_out = pd.DataFrame({\n",
    "    \"row_id\": meta_train[\"row_id\"].values,\n",
    "    \"TransactionDT\": meta_train[\"TransactionDT\"].values,\n",
    "    \"y_true\": y_meta_train,\n",
    "    \"has_oof\": has_oof,\n",
    "    \"fold\": oof_fold,\n",
    "    \"meta_proba\": oof_meta,\n",
    "    \"pred_label\": np.where(has_oof, (oof_meta >= THRESHOLD).astype(int), np.nan),\n",
    "    \"threshold_used\": np.where(has_oof, THRESHOLD, np.nan),\n",
    "})\n",
    "\n",
    "test_out = pd.DataFrame({\n",
    "    \"row_id\": meta_test[\"row_id\"].values,\n",
    "    \"TransactionDT\": meta_test[\"TransactionDT\"].values,\n",
    "    \"y_true\": y_meta_test,\n",
    "    \"meta_proba\": meta_test_proba,\n",
    "    \"pred_label\": (meta_test_proba >= THRESHOLD).astype(int),\n",
    "    \"threshold_used\": THRESHOLD,\n",
    "})\n",
    "\n",
    "oof_path = os.path.join(datapath, \"oof_meta.csv\")\n",
    "test_path = os.path.join(datapath, \"test_meta.csv\")\n",
    "oof_out.to_csv(oof_path, index=False)\n",
    "test_out.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"Saved:\", oof_path)\n",
    "print(\"Saved:\", test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# SHAP for meta model (very interpretable: only base-model signal features (now 4 if CatBoost included))\n",
    "# -----------------------------\n",
    "import shap\n",
    "\n",
    "# Use a small sample for plotting\n",
    "SAMPLE_SIZE = min(2000, len(X_meta_train))\n",
    "idx = np.random.RandomState(SEED).choice(len(X_meta_train), size=SAMPLE_SIZE, replace=False)\n",
    "X_shap = pd.DataFrame(X_meta_train[idx], columns=feature_cols)\n",
    "\n",
    "explainer = shap.TreeExplainer(meta_model)\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "# shap_values for binary can be list; normalize\n",
    "if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "    shap_vals_to_plot = shap_values[1]\n",
    "else:\n",
    "    shap_vals_to_plot = shap_values\n",
    "\n",
    "shap.summary_plot(shap_vals_to_plot, X_shap, show=False)\n",
    "plt.title(\"Meta XGBoost – SHAP Summary (Train Sample)\")\n",
    "plt.show()\n",
    "\n",
    "shap.summary_plot(shap_vals_to_plot, X_shap, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Meta XGBoost – SHAP Importance (Train Sample)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
