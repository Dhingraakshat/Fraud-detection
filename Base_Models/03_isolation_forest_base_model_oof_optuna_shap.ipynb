{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab25383",
   "metadata": {},
   "source": [
    "# 03 – Isolation Forest Base Model (OOF + Test)  \n",
    "This notebook trains an **Isolation Forest** anomaly detector on the scaled + one-hot encoded dataset produced by:\n",
    "\n",
    "- `01_preprocessing_real_time_split.ipynb`\n",
    "\n",
    "It produces:\n",
    "- `oof_iforest.csv` (out-of-fold anomaly *risk scores* for the **train** period)\n",
    "- `test_iforest.csv` (risk scores for the **future test** period)\n",
    "\n",
    "Key requirements implemented:\n",
    "- **TimeSeriesSplit** for OOF (no leakage)\n",
    "- **Optuna** hyperparameter tuning to maximize **F2-score** at a fixed threshold\n",
    "- Converts raw anomaly scores to a **0–1 risk score** via **MinMax scaling** (fit on train fold only)\n",
    "- **Confusion matrix** + metrics on the **test** period (labels used only for evaluation)\n",
    "- **SHAP** explanation (TreeExplainer if available; otherwise Kernel fallback)\n",
    "\n",
    "> Threshold is set to `0.05` by default (change once at the top and it updates everywhere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (Optional) Install dependencies (Colab-safe)\n",
    "try:\n",
    "    import optuna  # noqa: F401\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"optuna\"])\n",
    "\n",
    "try:\n",
    "    import shap  # noqa: F401\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"shap\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    fbeta_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Global config (EDIT HERE)\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "N_SPLITS = 5\n",
    "N_TRIALS = 30\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Detect Colab + mount Drive\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "datapath = \"/content/drive/MyDrive/RThesis/\" if IN_COLAB else \"./\"\n",
    "os.makedirs(datapath, exist_ok=True)\n",
    "\n",
    "print(\"datapath =\", datapath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load preprocessed scaled datasets\n",
    "# -----------------------------\n",
    "X_train_path = os.path.join(datapath, \"X_train_scaled.csv\")\n",
    "X_test_path  = os.path.join(datapath, \"X_test_scaled.csv\")\n",
    "y_train_path = os.path.join(datapath, \"y_train.csv\")\n",
    "y_test_path  = os.path.join(datapath, \"y_test.csv\")\n",
    "train_keys_path = os.path.join(datapath, \"train_keys.csv\")\n",
    "test_keys_path  = os.path.join(datapath, \"test_keys.csv\")\n",
    "\n",
    "for p in [X_train_path, X_test_path, y_train_path, y_test_path, train_keys_path, test_keys_path]:\n",
    "    assert os.path.exists(p), f\"Missing file: {p}\"\n",
    "\n",
    "X_train = pd.read_csv(X_train_path)\n",
    "X_test  = pd.read_csv(X_test_path)\n",
    "\n",
    "y_train = pd.read_csv(y_train_path)[\"isFraud\"].astype(int)\n",
    "y_test  = pd.read_csv(y_test_path)[\"isFraud\"].astype(int)\n",
    "\n",
    "train_keys = pd.read_csv(train_keys_path)\n",
    "test_keys  = pd.read_csv(test_keys_path)\n",
    "\n",
    "row_id_train = train_keys[\"row_id\"].values if \"row_id\" in train_keys.columns else np.arange(len(X_train))\n",
    "row_id_test  = test_keys[\"row_id\"].values if \"row_id\" in test_keys.columns else np.arange(len(X_test))\n",
    "\n",
    "assert len(X_train) == len(y_train) == len(row_id_train), \"Train alignment mismatch\"\n",
    "assert len(X_test)  == len(y_test)  == len(row_id_test), \"Test alignment mismatch\"\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \" | fraud rate:\", y_train.mean())\n",
    "print(\"X_test :\", X_test.shape,  \" | fraud rate:\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c706cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def compute_f2(y_true, y_score, threshold=THRESHOLD, beta=2.0):\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "    return fbeta_score(y_true, y_pred, beta=beta, zero_division=0)\n",
    "\n",
    "def evaluate_binary(y_true, y_score, threshold=THRESHOLD, title=\"Model\"):\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f2   = fbeta_score(y_true, y_pred, beta=2.0, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "    try:\n",
    "        ap = average_precision_score(y_true, y_score)\n",
    "    except Exception:\n",
    "        ap = np.nan\n",
    "\n",
    "    print(f\"\\n[{title}]  threshold={threshold}\")\n",
    "    print(f\"Precision: {prec:.4f} | Recall: {rec:.4f} | F2: {f2:.4f} | ROC-AUC: {auc:.4f} | PR-AUC: {ap:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm)\n",
    "    ax.set_title(f\"{title} – Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    ax.set_xticklabels([\"Non-Fraud\",\"Fraud\"])\n",
    "    ax.set_yticklabels([\"Non-Fraud\",\"Fraud\"])\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC + PR curves\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "        plt.title(f\"{title} – ROC Curve\")\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"ROC curve skipped:\", e)\n",
    "\n",
    "    try:\n",
    "        p, r, _ = precision_recall_curve(y_true, y_score)\n",
    "        plt.figure()\n",
    "        plt.plot(r, p)\n",
    "        plt.title(f\"{title} – Precision-Recall Curve\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"PR curve skipped:\", e)\n",
    "\n",
    "    return {\"precision\": prec, \"recall\": rec, \"f2\": f2, \"roc_auc\": auc, \"pr_auc\": ap, \"cm\": cm}\n",
    "\n",
    "def raw_anomaly_score(model: IsolationForest, X: pd.DataFrame) -> np.ndarray:\n",
    "    # IsolationForest: decision_function is higher for inliers, lower for outliers.\n",
    "    # Convert so that higher = more anomalous (fraud risk).\n",
    "    return (-model.decision_function(X)).astype(float)\n",
    "\n",
    "def scaled_score_from_train(train_raw: np.ndarray, other_raw: np.ndarray):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_raw.reshape(-1, 1))\n",
    "    return scaler, scaler.transform(other_raw.reshape(-1, 1)).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e563eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Optuna hyperparameter tuning (maximize mean CV F2)\n",
    "# -----------------------------\n",
    "def make_params(trial):\n",
    "    return {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 800),\n",
    "        \"max_samples\": trial.suggest_float(\"max_samples\", 0.4, 1.0),\n",
    "        \"max_features\": trial.suggest_float(\"max_features\", 0.4, 1.0),\n",
    "        \"contamination\": trial.suggest_float(\"contamination\", 0.001, 0.1, log=True),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [False, True]),\n",
    "        \"random_state\": SEED,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "def objective(trial):\n",
    "    params = make_params(trial)\n",
    "    tss = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "    f2s = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tss.split(X_train), start=1):\n",
    "        X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "        y_va = y_train.iloc[va_idx]\n",
    "\n",
    "        model = IsolationForest(**params)\n",
    "        model.fit(X_tr)\n",
    "\n",
    "        tr_raw = raw_anomaly_score(model, X_tr)\n",
    "        va_raw = raw_anomaly_score(model, X_va)\n",
    "\n",
    "        _, va_score = scaled_score_from_train(tr_raw, va_raw)\n",
    "        f2s.append(compute_f2(y_va.values, va_score, threshold=THRESHOLD))\n",
    "\n",
    "    return float(np.mean(f2s))\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"iforest_f2\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"Best CV F2:\", study.best_value)\n",
    "print(\"Best params:\\n\", json.dumps(best_params, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Final params + save\n",
    "# -----------------------------\n",
    "final_params = {**best_params, \"random_state\": SEED, \"n_jobs\": -1, \"verbose\": 0}\n",
    "\n",
    "best_params_path = os.path.join(datapath, \"best_params_iforest.json\")\n",
    "with open(best_params_path, \"w\") as f:\n",
    "    json.dump(final_params, f, indent=2)\n",
    "print(\"Saved best params to:\", best_params_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Generate OOF anomaly risk scores (0–1) with best params\n",
    "# Note: TimeSeriesSplit does NOT give OOF for the very first chunk.\n",
    "# Those rows remain NaN and are excluded from meta training (no leakage).\n",
    "# -----------------------------\n",
    "tss = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "\n",
    "oof_score = np.full(len(X_train), np.nan, dtype=float)\n",
    "oof_fold = np.full(len(X_train), -1, dtype=int)\n",
    "has_oof = np.zeros(len(X_train), dtype=bool)\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(tss.split(X_train), start=1):\n",
    "    X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "    y_va = y_train.iloc[va_idx]\n",
    "\n",
    "    model = IsolationForest(**final_params)\n",
    "    model.fit(X_tr)\n",
    "\n",
    "    tr_raw = raw_anomaly_score(model, X_tr)\n",
    "    va_raw = raw_anomaly_score(model, X_va)\n",
    "\n",
    "    _, va_score = scaled_score_from_train(tr_raw, va_raw)\n",
    "    oof_score[va_idx] = va_score\n",
    "    oof_fold[va_idx] = fold\n",
    "    has_oof[va_idx] = True\n",
    "\n",
    "    print(f\"Fold {fold}/{N_SPLITS} F2={compute_f2(y_va.values, va_score):.4f}\")\n",
    "\n",
    "# Evaluate OOF only where we actually have OOF predictions\n",
    "mask = has_oof\n",
    "_ = evaluate_binary(y_train.values[mask], oof_score[mask], threshold=THRESHOLD, title=\"IsolationForest OOF (Train)\")\n",
    "print(\"OOF coverage:\", mask.mean(), \"(fraction of train rows used for meta)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a414b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Fit final model on FULL train (unsupervised), score test\n",
    "# -----------------------------\n",
    "final_model = IsolationForest(**final_params)\n",
    "final_model.fit(X_train)\n",
    "\n",
    "train_raw_full = raw_anomaly_score(final_model, X_train)\n",
    "test_raw = raw_anomaly_score(final_model, X_test)\n",
    "\n",
    "scaler_full = MinMaxScaler()\n",
    "scaler_full.fit(train_raw_full.reshape(-1, 1))\n",
    "test_score = scaler_full.transform(test_raw.reshape(-1, 1)).ravel()\n",
    "\n",
    "_ = evaluate_binary(y_test.values, test_score, threshold=THRESHOLD, title=\"IsolationForest (Test)\")\n",
    "\n",
    "# Save outputs\n",
    "oof_df = pd.DataFrame({\n",
    "    \"row_id\": row_id_train,\n",
    "    \"y_true\": y_train.values,\n",
    "    \"has_oof\": has_oof,\n",
    "    \"fold\": oof_fold,\n",
    "    \"iforest_score\": oof_score,\n",
    "    \"pred_label\": np.where(has_oof, (oof_score >= THRESHOLD).astype(int), np.nan),\n",
    "    \"threshold_used\": np.where(has_oof, THRESHOLD, np.nan),\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"row_id\": row_id_test,\n",
    "    \"y_true\": y_test.values,\n",
    "    \"iforest_score\": test_score,\n",
    "    \"pred_label\": (test_score >= THRESHOLD).astype(int),\n",
    "    \"threshold_used\": THRESHOLD,\n",
    "})\n",
    "\n",
    "oof_path  = os.path.join(datapath, \"oof_iforest.csv\")\n",
    "test_path = os.path.join(datapath, \"test_iforest.csv\")\n",
    "oof_df.to_csv(oof_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"Saved:\", oof_path)\n",
    "print(\"Saved:\", test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# SHAP – explain anomaly risk score\n",
    "# -----------------------------\n",
    "import shap\n",
    "\n",
    "SAMPLE_SIZE = min(500, len(X_test))\n",
    "shap_sample = X_test.sample(n=SAMPLE_SIZE, random_state=SEED)\n",
    "\n",
    "# Try TreeExplainer first (fast for tree models). If it fails, fallback to KernelExplainer (slow).\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(final_model)\n",
    "    shap_values = explainer.shap_values(shap_sample)\n",
    "\n",
    "    # Some SHAP versions return list; normalize\n",
    "    if isinstance(shap_values, list) and len(shap_values) > 0:\n",
    "        shap_vals_to_plot = shap_values[0]\n",
    "    else:\n",
    "        shap_vals_to_plot = shap_values\n",
    "\n",
    "    shap.summary_plot(shap_vals_to_plot, shap_sample, show=False)\n",
    "    plt.title(\"IsolationForest – SHAP Summary (Test Sample)\")\n",
    "    plt.show()\n",
    "\n",
    "    shap.summary_plot(shap_vals_to_plot, shap_sample, plot_type=\"bar\", show=False)\n",
    "    plt.title(\"IsolationForest – SHAP Importance (Test Sample)\")\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"TreeExplainer failed; using KernelExplainer fallback. Reason:\", repr(e))\n",
    "\n",
    "    background = X_train.sample(n=min(100, len(X_train)), random_state=SEED)\n",
    "\n",
    "    def score_fn(X_np):\n",
    "        X_df = pd.DataFrame(X_np, columns=X_train.columns)\n",
    "        raw = raw_anomaly_score(final_model, X_df)\n",
    "        return scaler_full.transform(raw.reshape(-1, 1)).ravel()\n",
    "\n",
    "    explainer = shap.KernelExplainer(score_fn, background)\n",
    "    shap_values = explainer.shap_values(shap_sample, nsamples=200)\n",
    "\n",
    "    shap.summary_plot(shap_values, shap_sample, show=False)\n",
    "    plt.title(\"IsolationForest – SHAP Summary (KernelExplainer, Test Sample)\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
